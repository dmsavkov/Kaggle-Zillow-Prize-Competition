{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c2658383",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import gc\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from lightgbm import LGBMClassifier, LGBMRegressor\n",
        "import scipy.stats as stats\n",
        "\n",
        "from zillow.config.feature_engineering import FeaturesDtypeConversionConfig_v1\n",
        "from zillow.utils.common import read_data, find_shared_cols, find_unshared_cols, get_feat_nature_types, throw_col_not_exist_warning, modify_dataclass\n",
        "from zillow.config.config import load_config_no_wrap, create_config_from_dict, merge_configs\n",
        "from zillow.config.paths import PROCESSED_DATA_DIR, RAW_DATA_DIR, INTERIM_DATA_DIR, REPORTS_DIR, ANALYSIS_RESULTS_DIR\n",
        "\n",
        "cfg = load_config_no_wrap('default')\n",
        "cur_cfg = create_config_from_dict({\n",
        "    'load_all_data': False,\n",
        "    'main_train_path': INTERIM_DATA_DIR / 'cleaned_train_2016_v1.0.parquet',\n",
        "    'main_test_path': INTERIM_DATA_DIR / 'cleaned_properties_2016_v1.0.parquet',\n",
        "})\n",
        "cfg = merge_configs(cfg, cur_cfg)\n",
        "\n",
        "np.random.seed(cfg.RSEED)\n",
        "plt.style.use('seaborn-v0_8-whitegrid')\n",
        "sns.set_palette(\"deep\")\n",
        "\n",
        "zillow_dictionary = pd.read_csv(RAW_DATA_DIR / \"zillow_data_dictionary.csv\")\n",
        "\n",
        "if cfg.to_load_all_data:\n",
        "    properties_2016 = read_data(path=INTERIM_DATA_DIR / \"cleaned_properties_2016_v1.0.parquet\", dtype='default')\n",
        "    properties_2017 = read_data(path=INTERIM_DATA_DIR / \"cleaned_properties_2017_v1.0.parquet\", dtype='default')\n",
        "    train_2016 = read_data(path=INTERIM_DATA_DIR / \"cleaned_train_2016_v1.0.parquet\", dtype='default')\n",
        "    train_2017 = read_data(path=INTERIM_DATA_DIR / \"cleaned_train_2017_v1.0.parquet\", dtype='default')\n",
        "\n",
        "train = read_data(cfg.main_train_path, dtype='default')\n",
        "\n",
        "features_dtype_cfg = FeaturesDtypeConversionConfig_v1()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "d80d3b62",
      "metadata": {},
      "outputs": [],
      "source": [
        "def split_time_series_2016(df_file_name=MAIN_TRAIN_FILENAME):\n",
        "    train_path = f\"{DATA_DIR}train_train_2016.parquet\"\n",
        "    val_path = f\"{DATA_DIR}val_train_2016.parquet\"\n",
        "    if os.path.exists(train_path) and os.path.exists(val_path):\n",
        "        return read_data(train_path, dtype='default'), read_data(val_path, dtype='default')\n",
        "\n",
        "    df = read_data(path=f\"{DATA_DIR}{df_file_name}\", dtype='default')\n",
        "    val = df[df['trans_month'].isin([10, 11, 12])].copy()\n",
        "    train = df[~df.index.isin(val.index)].copy()\n",
        "\n",
        "    drop_cols = features_dtype_cfg.dtype_break_down_mapping['date'].keys()\n",
        "    train.drop(columns=drop_cols, inplace=True)\n",
        "    val.drop(columns=drop_cols, inplace=True)\n",
        "\n",
        "    val.reset_index(drop=True, inplace=True)\n",
        "    train.reset_index(drop=True, inplace=True)\n",
        "\n",
        "    val.to_parquet(val_path)\n",
        "    train.to_parquet(train_path)\n",
        "\n",
        "    return train, val"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "62d7de5a",
      "metadata": {},
      "source": [
        "#### Baseline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "06079f98",
      "metadata": {},
      "outputs": [],
      "source": [
        "test = read_data(path=f\"{DATA_DIR}{MAIN_TEST_FILENAME}\", dtype='default')\n",
        "test = test.drop(columns=['assessmentyear', cfg.index_col])\n",
        "\n",
        "train, val = split_time_series_2016(df_file_name=MAIN_TRAIN_FILENAME)\n",
        "model = LGBMRegressor(\n",
        "    random_state=cfg.RSEED\n",
        ")\n",
        "\n",
        "validation = Validation(\n",
        "    train,\n",
        "    val,\n",
        "    model, \n",
        "    cfg.target,\n",
        "    metric='neg_mean_absolute_error', \n",
        "    cv=10\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a2bc0a54",
      "metadata": {},
      "outputs": [],
      "source": [
        "def run_validation(validation):\n",
        "    split_res = validation.run_split()\n",
        "    cv_res = abs(validation.run_cross_validation())\n",
        "    tm_res = abs(validation.run_tm_split())\n",
        "\n",
        "    cv_diff = abs(split_res['mae'] - cv_res.mean())\n",
        "    tm_diff = abs(split_res['mae'] - tm_res.mean())\n",
        "    print(f\"Result: {split_res}, with cv difference: {cv_diff}, and tm cv {tm_diff}.\")\n",
        "\n",
        "def run_submission(train, test):\n",
        "    X = train.drop(columns=[cfg.index_col, cfg.target])\n",
        "    model.fit(X, train[cfg.target])\n",
        "    ypred = model.predict(test)\n",
        "\n",
        "    submission = Submission(ypred, sample_submission['ParcelId'])\n",
        "    submission.save_submission(\"lgbmr_baseline_2016.csv\", SUBMISSIONS_PATH)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
